# GEMMurai ğŸ¥‹âš”ï¸ğŸ™‡

*The Way of the Matrix Warrior*

A training dojo for mastering high-performance linear algebra from first principles. This is not a production libraryâ€”it's a forge for understanding how the masters like Kazushige Goto achieved computational enlightenment.

## The Path

Transform abstract linear algebra theory into blazing fast kernels. From Axler's vector spaces to hand-tuned assembly that rivals commercial BLAS implementations. (ambition is $\frac{7}{10}$ths of the way).

### The Three Sacred Levels

**BLAS Level 1** - *The Foundation* 
- Vector-vector operations: `O(n)` work on `O(n)` data
- Operations: dot products (`dot`), vector scaling (`scal`), addition (`axpy`)
- *Sensei says: "Master the simple before attempting the complex"*

**BLAS Level 2** - *The Ascension*
- Matrix-vector operations: `O(nÂ²)` work on `O(nÂ²)` data  
- Operations: matrix-vector multiply (`gemv`), rank-1 updates (`ger`)
- *Where cache awareness begins to matter*

**BLAS Level 3** - *The Mastery*
- Matrix-matrix operations: `O(nÂ³)` work on `O(nÂ²)` data
- The holy grail: `GEMM` (General Matrix Multiply)
- *Optimal arithmetic intensity, where legends are forged*

## Training Philosophy

- **Rigor First**: Understand the mathematics (Axler â†’ Trefethen & Bau)
- **Measure Everything**: Profile-driven optimization, not premature cleverness
- **Incremental Mastery**: Generic C â†’ Cache blocking â†’ SIMD â†’ Assembly
- **No Shortcuts**: Build intuition through implementation

## Current Kata

- [ ] Basic BLAS-1 implementations
- [ ] Cache-conscious GEMV
- [ ] The legendary GEMM kernel
- [ ] Assembly optimization passes
- [ ] Benchmark against OpenBLAS/MKL

*Î´á¿¶Ï‚ Î¼Î¿Î¹ Ï€á¾¶ ÏƒÏ„á¿¶ ÎºÎ±á½¶ Ï„á½°Î½ Î³á¾¶Î½ ÎºÎ¹Î½Î¬ÏƒÏ‰*

*é“ã¯é•·ã„*
